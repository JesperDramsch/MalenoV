{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-dimensional seismic facies classification using CNNs\n",
    "\n",
    "By: Charles Rutherford Ildstad (University of Trondheim), as part of a summer intern project in ConocoPhillips and private work\n",
    "\n",
    "Contributions from Anders U. Waldeland (University of Oslo), Chris Olsen (ConocoPhillips), Doug Hakkarinen (ConocoPhillips)\n",
    "\n",
    "- Date: 26.10.2017\n",
    "- For: ConocoPhillips, Norway,\n",
    "- GNU V3.0 lesser license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import malenov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducability\n",
    "np.random.seed(42)\n",
    "# Confirm backend if in doubt\n",
    "#keras.backend.backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ---- Run an instance of the master function ----\n",
    "filenames=['PGS16902VIK_pstm_ang08_17_dec_crop','PGS16902VIK_pstm_ang17_27_dec_crop', 'PGS16902VIK_pstm_ang27_33_dec_crop']    # name of the segy-cube(s) with data\n",
    "inp_res = np.float32    # formatting of the input seismic (e.g. np.int8 for 8-bit data, np.float32 for 32-bit data, etc)\n",
    "cube_incr = 32    # number of increments in each direction to create a training cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the dictionary holding all the training parameters\n",
    "train_dict = {\n",
    "    'files' : ['multi_channel_new.pts','multi_coherent.pts','multi_else.pts','multi_fault.pts','multi_grid.pts','multi_grizzly.pts'],    # list of names of class-adresses\n",
    "    'num_tot_iterations': 25,    # number of times we draw a new training ensemble/mini-batch\n",
    "    'epochs' : 12,    # number of epochs we run on each training ensemble/mini-batch\n",
    "    'num_train_ex' : 18000,    # number of training examples in each training ensemble/mini-batch\n",
    "    'batch_size' : 32,    # number of training examples fed to the optimizer as a batch\n",
    "    'opt_patience' : 10,    # number of epochs with the same accuracy before force breaking the training ensemble/mini-batch\n",
    "    'data_augmentation' : False,    # whether or not we are using data augmentation\n",
    "    'save_model' : True,    # whether or not we are saving the trained model\n",
    "    'save_location' : 'F3_train'    # file name for the saved trained model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'mulitvolume_multifacies.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3c9856de9649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define the dictionary holding all the prediction parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m pred_dict = {\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;34m'keras_model'\u001b[0m \u001b[1;33m:\u001b[0m  \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mulitvolume_multifacies.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# input model to be used for prediction, to load a model use: keras.models.load_model('write_location')\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;34m'section_edge'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m33282\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m33282\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m123898\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m123900\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2840\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# inline and xline section to be predicted (all depths), must contain xline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'show_feature'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[1;31m# Show the distinct features before they are combined to a prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\malenov\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         \u001b[1;31m# instantiate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\malenov\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\malenov\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'mulitvolume_multifacies.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Define the dictionary holding all the prediction parameters\n",
    "pred_dict = {\n",
    "    'keras_model' :  keras.models.load_model('mulitvolume_multifacies.h5'), # input model to be used for prediction, to load a model use: keras.models.load_model('write_location')\n",
    "    'section_edge' : np.asarray([33282, 33282, 123898, 123900, 128, 2840]), # inline and xline section to be predicted (all depths), must contain xline\n",
    "    'show_feature' : False,    # Show the distinct features before they are combined to a prediction\n",
    "    'xline' : 123900,    # xline used for classification (index)(should be within section range)\n",
    "    'num_class' : len(train_dict['files']),    # number of classes to output\n",
    "    'cord_syst' : 'segy',    # Coordinate system used, default is 0,0. Set to 'segy' to give inputs in (inline,xline)\n",
    "    'save_pred' : True,    # Save the prediction as a segy-cube\n",
    "    'save_location' : 'sunday.segy',     # file name for the saved prediction\n",
    "    'pred_batch' : 25,     # number of traces used to make batches of mini-cubes that are stored in memory at once\n",
    "    #'pred_batch' : train_dict['num_train_ex']//(pred_dict['section_edge'][5]-pred_dict['section_edge'][4])    #Suggested value\n",
    "    'pred_prob' : False     # Give the probabilities of the first class(True), or simply show where each class is classified(False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the master function and save the output in the output dictionary output_dict\n",
    "output_dict1 = malenov(\n",
    "    segy_filename = filenames,     # Seismic filenames\n",
    "    inp_format = inp_res,     # Format of input seismic\n",
    "    cube_incr = cube_incr,     # Increments in each direction to create a training cube\n",
    "    train_dict = train_dict,     # Input training dictionary\n",
    "    pred_dict = pred_dict,     # Input prediction dictionary\n",
    "    mode = 'predict'     # Input mode ('train', 'predict', or 'full' for both training AND prediction)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show additional details about the prediciton\n",
    "show_details(\n",
    "    filename,\n",
    "    cube_incr,\n",
    "    output_dict['pred'],\n",
    "    inline = 100,\n",
    "    inl_start = 75,\n",
    "    xline = 169,\n",
    "    xl_start = 155,\n",
    "    slice_number = 400,\n",
    "    slice_incr = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save/load functions\n",
    "# returns a prediction cube\n",
    "# identical to the one saved\n",
    "prediction = np.load('filename.npy')\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the one saved\n",
    "loaded_model = keras.models.load_model('filename.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:malenov]",
   "language": "python",
   "name": "conda-env-malenov-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
