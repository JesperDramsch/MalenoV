{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-dimensional seismic facies classification using CNNs\n",
    "\n",
    "By: Charles Rutherford Ildstad (University of Trondheim), as part of a summer intern project in ConocoPhillips and private work\n",
    "\n",
    "Contributions from Anders U. Waldeland (University of Oslo), Chris Olsen (ConocoPhillips), Doug Hakkarinen (ConocoPhillips)\n",
    "\n",
    "- Date: 26.10.2017\n",
    "- For: ConocoPhillips, Norway,\n",
    "- GNU V3.0 lesser license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import malenov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducability\n",
    "np.random.seed(42)\n",
    "# Confirm backend if in doubt\n",
    "#keras.backend.backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ---- Run an instance of the master function ----\n",
    "filedir='Dutch F3 seismic data/'\n",
    "filenames=['multi_facies Prediction_F3_10ep10it_60k_samples.segy']    # name(s) of the segy-cube(s) with data\n",
    "inp_res = np.float32    # formatting of the input seismic (e.g. np.int8 for 8-bit data, np.float32 for 32-bit data, etc)\n",
    "cube_incr = 32    # number of increments in each direction to create a training cube\n",
    "fileloc=[filedir+j for j in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the dictionary holding all the training parameters\n",
    "\n",
    "pts_files = ['multi_else_ilxl.pts','multi_grizzly_ilxl.pts','multi_high_amp_continuous_ilxl.pts','multi_high_amplitude_ilxl.pts','multi_low_amp_dips_ilxl.pts','multi_low_amplitude_ilxl.pts','multi_low_coherency_ilxl.pts','multi_salt_ilxl.pts','multi_steep_dips_ilxl.pts']    # list of names of class-adresses\n",
    "\n",
    "train_dict = {\n",
    "    'files': [filedir+j for j in pts_files],\n",
    "    'num_tot_iterations': 25,    # number of times we draw a new training ensemble/mini-batch\n",
    "    'epochs' : 12,    # number of epochs we run on each training ensemble/mini-batch\n",
    "    'num_train_ex' : 18000,    # number of training examples in each training ensemble/mini-batch\n",
    "    'batch_size' : 32,    # number of training examples fed to the optimizer as a batch\n",
    "    'opt_patience' : 10,    # number of epochs with the same accuracy before force breaking the training ensemble/mini-batch\n",
    "    'data_augmentation' : False,    # whether or not we are using data augmentation\n",
    "    'save_model' : True,    # whether or not we are saving the trained model\n",
    "    'save_location' : filedir+'F3_train'    # file name for the saved trained model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the dictionary holding all the prediction parameters\n",
    "from keras.models import load_model\n",
    "\n",
    "pred_dict = {\n",
    "    'keras_model' :  load_model(filedir+'Trained model multi_facies_F3_10ep10it_35ksamples.h5'), # input model to be used for prediction, to load a model use: keras.models.load_model('write_location')\n",
    "    'section_edge' : np.asarray([33282, 33282, 123898, 123900, 128, 2840]), # inline and xline section to be predicted (all depths), must contain xline\n",
    "    'show_feature' : False,    # Show the distinct features before they are combined to a prediction\n",
    "    'xline' : 123900,    # xline used for classification (index)(should be within section range)\n",
    "    'num_class' : len(train_dict['files']),    # number of classes to output\n",
    "    'cord_syst' : 'segy',    # Coordinate system used, default is 0,0. Set to 'segy' to give inputs in (inline,xline)\n",
    "    'save_pred' : True,    # Save the prediction as a segy-cube\n",
    "    'save_location' : filedir+'sunday.segy',     # file name for the saved prediction\n",
    "    'pred_batch' : 25,     # number of traces used to make batches of mini-cubes that are stored in memory at once\n",
    "    #'pred_batch' : train_dict['num_train_ex']//(pred_dict['section_edge'][5]-pred_dict['section_edge'][4])    #Suggested value\n",
    "    'pred_prob' : False     # Give the probabilities of the first class(True), or simply show where each class is classified(False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the master function and save the output in the output dictionary output_dict\n",
    "\n",
    "output_dict1 = malenov.master(\n",
    "    segy_filename = fileloc,     # Seismic filenames\n",
    "    inp_format = inp_res,     # Format of input seismic\n",
    "    cube_incr = cube_incr,     # Increments in each direction to create a training cube\n",
    "    train_dict = train_dict,     # Input training dictionary\n",
    "    pred_dict = pred_dict,     # Input prediction dictionary\n",
    "    mode = 'predict'     # Input mode ('train', 'predict', or 'full' for both training AND prediction)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show additional details about the prediciton\n",
    "show_details(\n",
    "    filename,\n",
    "    cube_incr,\n",
    "    output_dict['pred'],\n",
    "    inline = 100,\n",
    "    inl_start = 75,\n",
    "    xline = 169,\n",
    "    xl_start = 155,\n",
    "    slice_number = 400,\n",
    "    slice_incr = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save/load functions\n",
    "# returns a prediction cube\n",
    "# identical to the one saved\n",
    "prediction = np.load('filename.npy')\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the one saved\n",
    "loaded_model = keras.models.load_model('filename.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:malenov]",
   "language": "python",
   "name": "conda-env-malenov-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
